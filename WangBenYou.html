<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Generic - Hyperspace by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<a href="index.html" class="title">QCAI2020</a>
				<nav>
					<ul>
						<li><a href="index.html">Home</a></li>
						<li><a href="generic.html" class="active">Members</a></li>
						
					</ul>
				</nav>
			</header>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<section id="main" class="wrapper">
						<div class="inner" align="center">
							<h1 class="major">王本有 博士</h1>
							<span class="image fit"><img src="images/WangBenYou.png" style="width:220px;height:310px" alt="" /></span>
							<font size="5" ><p align="left">报告题目：How quantum theory contributes to NLP?</p></font>
							<font size="5" ><p align="left">报告摘要： Quantum theory and quantum computation are naturally suited to managing data in a high dimensional space,  in which data may be superposed and also entangle with each other. Interestingly, such superposition principles and entanglement phenomena can arguably be found in natural language. Recently, natural language processing has been largely improved by using large-scale pretraining language models with massive cheap unstructured corpora and huge neural networks (e.g., BERT, GPT, etc.).  Such neural networks dealing with massive data may therefore benefit from quantum theory, especially processing large-amount high-dimensional data in BERT and GPT. How quantum theory contributes to NLP in the context of large-scale pretraining language models is worthy investigated. In this report,  many aspects of processing natural language,  e.g., efficiency, effectiveness, interpretability, and semantic cognition, will be discussed with quantum theory.</p></font>
							<font size="5" ><p align="left">专家简介：王本友，意大利帕多瓦大学博士生，欧盟玛丽居里研究员。在天津大学获得硕士学位，曾在丹麦哥本哈根大学，加拿大蒙特利尔大学，荷兰阿姆斯特丹大学，华为诺亚方舟实验室交流访问，多次受邀在MILA，头条，腾讯，华为等研究所和企业做主题报告。在工业应用方面，他2017年开始曾在腾讯全职工作，作为主要算法设计人员，在腾讯云上从零搭建了稳健的智能客服系统，服务中国银行，云南省旅游局等头部客户；并与腾讯同事合写的《推荐系统与深度学习》由清华大学出版社出版。在相对较短的学术生涯，他致力于构建更加鲁棒和智能的自然语言处理系统，兼顾技术合理性和语言学动机。迄今他和他的合作者一起获得了国际信息检索顶级会议SIGIR 2017最佳论文提名奖和国际自然语言处理顶级会议NAACL 2019最佳可解释论文，发表了包括国际顶级会议ICLR/SIGIR/WWW/NAACL/AAAI/IJCAI/CIKM等20余篇.</p>
						</div>
					</section>

			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper alt">
				<div class="inner">
					<ul class="menu">
						<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>